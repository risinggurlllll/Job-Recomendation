{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip install nltk\\n\\npip install spacy==2.3.5\\n\\npip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\\n\\npip install pyresparser'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< INSTALLATION GUIDE>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \n",
    "\n",
    "'''pip install nltk\n",
    "\n",
    "pip install spacy==2.3.5\n",
    "\n",
    "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
    "\n",
    "pip install pyresparser'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "from nltk.collocations import *\n",
    "import base64,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'cv_to_df/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Iterate through all files in the resumes directory\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresumes_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Check if the file is a PDF\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;66;03m# Apply the ResumeParser function to the current file and append the extracted data to the DataFrame\u001b[39;00m\n\u001b[0;32m     32\u001b[0m         data \u001b[38;5;241m=\u001b[39m ResumeParser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(resumes_dir, filename))\u001b[38;5;241m.\u001b[39mget_extracted_data()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'cv_to_df/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyresparser import ResumeParser\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "# Define the directory containing resumes\n",
    "resumes_dir = ' '\n",
    "resumes_dir_full_path = os.path.abspath(resumes_dir)\n",
    "\n",
    "def pdf_to_base64(file_path):\n",
    "    \n",
    "    encoded_pdf = base64.b64encode(file_path.read()).decode('utf-8')\n",
    "\n",
    "    return encoded_pdf\n",
    "\n",
    "def extract_text_from_pdf(filepath):\n",
    "    with pdfplumber.open(filepath) as pdf:\n",
    "        text = \"\"\n",
    "        pages = pdf.pages\n",
    "        for page in pages:\n",
    "            text += page.extract_text(x_tolerance=2)\n",
    "    return text\n",
    "\n",
    "# Create an empty DataFrame object to store the extracted data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate through all files in the resumes directory\n",
    "for filename in os.listdir(resumes_dir):\n",
    "    if filename.endswith('.pdf'):  # Check if the file is a PDF\n",
    "        # Apply the ResumeParser function to the current file and append the extracted data to the DataFrame\n",
    "        data = ResumeParser(os.path.join(resumes_dir, filename)).get_extracted_data()\n",
    "        # Add a new column to the DataFrame containing the file path\n",
    "        data['file_path'] = os.path.join(resumes_dir, filename)\n",
    "        # Append the extracted data to the DataFrame\n",
    "        df = df.append(data, ignore_index=True)\n",
    "\n",
    "# Extract text from all PDFs in the resumes directory and create a new DataFrame\n",
    "data = []\n",
    "for filename in os.listdir(resumes_dir):\n",
    "    if filename.endswith('.pdf'):\n",
    "        filepath = os.path.join(resumes_dir, filename)\n",
    "        resume_data = extract_text_from_pdf(filepath)\n",
    "        data.append({'file_path': filepath, 'All': resume_data})\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "# Merge the two data frames on the \"file_path\" column\n",
    "merged_df = pd.merge(df, df2, on='file_path')\n",
    "merged_df.drop(columns=[\"college_name\",\"company_names\",\"designation\",\"experience\",\"total_experience\"], axis=1, inplace=True) # dropping unwanted col\n",
    "\n",
    "# Define the regex pattern to match unwanted characters\n",
    "unwanted_chars_pattern = r'[^a-zA-Z !@#$%&*_+-=|\\:\";<>,./()[\\]{}\\']'\n",
    "for col in ['skills','degree', 'All']:\n",
    "    merged_df[col] = merged_df[col].apply(lambda x: re.sub(unwanted_chars_pattern, '', str(x)))\n",
    "\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['college_name', 'company_names', 'degree', 'designation', 'experience',\n",
       "       'no_of_pages', 'total_experience', 'All'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('cv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>degree</th>\n",
       "      <th>email</th>\n",
       "      <th>file_path</th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>name</th>\n",
       "      <th>no_of_pages</th>\n",
       "      <th>skills</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Jangrasukanya066@gmail.com</td>\n",
       "      <td>cv_to_df/3bdfa685-56f1-4f83-866c-dbb20be51048.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sukanya Jangra</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Html', 'C++', 'Javascript', 'Excel', 'Word',...</td>\n",
       "      <td>Sukanya JangraBhiwani, HaryanaJangrasukanya066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['Bachelor of Engineering,Computer Sciencenvis...</td>\n",
       "      <td>abhayownsthis@gmail.com</td>\n",
       "      <td>cv_to_df/abhay_kumar_visualcv_resume_with_GTC.pdf</td>\n",
       "      <td>9978045</td>\n",
       "      <td>Abhay Kumar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['Caffe', 'Modeling', 'Website', 'Training', '...</td>\n",
       "      <td>Abhay KumarLead Data Scientist - Computer Visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['Master of Engineering', 'Master in Computer ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cv_to_df/Abhijit-Manepatil.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abhijit Manepatil</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['Modeling', 'English', 'Gis', 'Website', 'Alg...</td>\n",
       "      <td>Abhijit ManepatilData Scientist with Master in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>abhi4navv@gmail.com</td>\n",
       "      <td>cv_to_df/Abhinav_Abhishek_visualcv_resume (1).pdf</td>\n",
       "      <td>8757656959</td>\n",
       "      <td>Abhinav Abhishek</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['Warehouse', 'Training', 'Networking', 'Datab...</td>\n",
       "      <td>Abhinav AbhishekSenior Software Developer/Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['Bachelor of Engineering, Computer Science  n...</td>\n",
       "      <td>monu.aniket@gmail.com</td>\n",
       "      <td>cv_to_df/Aniket_cv.pdf</td>\n",
       "      <td>9691316944</td>\n",
       "      <td>Aniket Kashyap</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['Website', 'Algorithms', 'Database', 'Visual'...</td>\n",
       "      <td>Aniket KashyapSoftware Developer/Data Scientis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             degree  \\\n",
       "0           0                                               None   \n",
       "1           1  ['Bachelor of Engineering,Computer Sciencenvis...   \n",
       "2           2  ['Master of Engineering', 'Master in Computer ...   \n",
       "3           3                                               None   \n",
       "4           4  ['Bachelor of Engineering, Computer Science  n...   \n",
       "\n",
       "                        email  \\\n",
       "0  Jangrasukanya066@gmail.com   \n",
       "1     abhayownsthis@gmail.com   \n",
       "2                         NaN   \n",
       "3         abhi4navv@gmail.com   \n",
       "4       monu.aniket@gmail.com   \n",
       "\n",
       "                                           file_path mobile_number  \\\n",
       "0  cv_to_df/3bdfa685-56f1-4f83-866c-dbb20be51048.pdf           NaN   \n",
       "1  cv_to_df/abhay_kumar_visualcv_resume_with_GTC.pdf       9978045   \n",
       "2                     cv_to_df/Abhijit-Manepatil.pdf           NaN   \n",
       "3  cv_to_df/Abhinav_Abhishek_visualcv_resume (1).pdf    8757656959   \n",
       "4                             cv_to_df/Aniket_cv.pdf    9691316944   \n",
       "\n",
       "                name  no_of_pages  \\\n",
       "0     Sukanya Jangra          1.0   \n",
       "1        Abhay Kumar          4.0   \n",
       "2  Abhijit Manepatil          3.0   \n",
       "3   Abhinav Abhishek          3.0   \n",
       "4     Aniket Kashyap          3.0   \n",
       "\n",
       "                                              skills  \\\n",
       "0  ['Html', 'C++', 'Javascript', 'Excel', 'Word',...   \n",
       "1  ['Caffe', 'Modeling', 'Website', 'Training', '...   \n",
       "2  ['Modeling', 'English', 'Gis', 'Website', 'Alg...   \n",
       "3  ['Warehouse', 'Training', 'Networking', 'Datab...   \n",
       "4  ['Website', 'Algorithms', 'Database', 'Visual'...   \n",
       "\n",
       "                                                 All  \n",
       "0  Sukanya JangraBhiwani, HaryanaJangrasukanya066...  \n",
       "1  Abhay KumarLead Data Scientist - Computer Visi...  \n",
       "2  Abhijit ManepatilData Scientist with Master in...  \n",
       "3  Abhinav AbhishekSenior Software Developer/Data...  \n",
       "4  Aniket KashyapSoftware Developer/Data Scientis...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyresparser import ResumeParser\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_base64(file_path):\n",
    "    #with pdfplumber.open(filepath) as pdf\n",
    "    with open(file_path, 'rb') as f:\n",
    "    \n",
    "        encoded_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    return encoded_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_files=[]\n",
    "for i in df[\"file_path\"].values:\n",
    "    print()\n",
    "    encoded_files.append(pdf_to_base64(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pdf_to_base64\"]=encoded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"updated_cv.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "d86ab636b363cb32d3f7578512f6396b4a169d210dbf8b4d547e88bd9fd74388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
